
        <!DOCTYPE html>
        <html>
        <head>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                table { border-collapse: collapse; width: 100%; }
                th, td { padding: 8px; text-align: left; border-bottom: 1px solid #ddd; }
                th { background-color: #f2f2f2; }
                tr:hover { 
                    background-color: #f5f5f5;
                    text-decoration: underline;
                    color: #0066cc;
                    cursor: pointer;
                }
                h1 { color: #333; }
                .filter-links { margin-bottom: 20px; }
                .filter-links a {
                    margin-right: 15px;
                    text-decoration: none;
                    color: #0066cc;
                    padding: 5px 10px;
                    border-radius: 3px;
                    cursor: pointer;
                }
                .filter-links a.active {
                    background-color: #0066cc;
                    color: white;
                }
                .hidden { display: none; }
            </style>
            <script>
                function filterByName(name) {
                    const rows = document.querySelectorAll('table tr[data-name]');
                    const links = document.querySelectorAll('.filter-links a');
                    
                    links.forEach(link => {
                        if (link.getAttribute('data-name') === name || (name === 'all' && link.getAttribute('data-name') === 'all')) {
                            link.classList.add('active');
                        } else {
                            link.classList.remove('active');
                        }
                    });
                    
                    rows.forEach(row => {
                        if (name === 'all' || row.getAttribute('data-name') === name) {
                            row.classList.remove('hidden');
                        } else {
                            row.classList.add('hidden');
                        }
                    });
                }

                function openUrl(url) {
                    window.open(url, '_blank');
                }
            </script>
        </head>
        <body>
        <h1>Citations for Pablo_Riera</h1><div class="filter-links">
<a onclick="filterByName('all')" data-name="all" class="active">All</a>
<a onclick="filterByName('Pablo_Riera')" data-name="Pablo_Riera">Pablo Riera</a>
</div>

        <table>
            <tr><th>Year</th><th>Citation</th></tr>
        <tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Automatic+Pronunciation+Assessment+Systems+for+English+Students+from+Argentina')"><td>2024</td><td>Vidal, Jazm\'ın, Bonomi, C., Riera, P., & Ferrer, L. (2024 , August). Automatic pronunciation assessment systems for english students from argentina. Commun. ACM, 67(8), 63–67. URL: https://doi.org/10.1145/3653326, doi:10.1145/3653326</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=EnCodecMAE%3A+Leveraging+neural+codecs+for+universal+audio+representation+learning')"><td>2024</td><td>Pepino, L., Riera, P., & Ferrer, L. (2024). EnCodecMAE: Leveraging neural codecs for universal audio representation learning.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=The+Unreliability+of+Acoustic+Systems+in+Alzheimer%27s+Speech+Datasets+with+Heterogeneous+Recording+Conditions')"><td>2024</td><td>Gauder, L., Riera, P., Slachevsky, A., Forno, G., Garcia, A. M., & Ferrer, L. (2024). The Unreliability of Acoustic Systems in Alzheimer's Speech Datasets with Heterogeneous Recording Conditions.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Toolkit+to+Examine+Lifelike+Language+%28TELL%29%3A+An+app+to+capture+speech+and+language+markers+of+neurodegeneration')"><td>2023</td><td>García, A. M., Johann, F., Echegoyen, R., Calcaterra, C., Riera, P., Belloli, L., & Carrillo, F. (2023). Toolkit to examine lifelike language (tell): an app to capture speech and language markers of neurodegeneration. Behavior Research Methods, pp. 1–15.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=An+embedded+wavetable+synthesizer+for+the+electronic+bandoneon+with+parameter+mappings+based+on+acoustical+measurements')"><td>2023</td><td>Ramos, J. M., Calcagno, E. R., & Riera, P. E. (2023). An embedded wavetable synthesizer for the electronic bandoneon with parameter mappings based on acoustical measurements. Proceedings of the International Conference on New Interfaces for Musical Expression.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=%7BTeamwork+Quality+Prediction+Using+Speech-Based+Features%7D')"><td>2023</td><td>Meza, M., Gauder, L., Estienne, L., Barchi, R., Gravano, A., Riera, P., & Ferrer, L. (2023). Teamwork Quality Prediction Using Speech-Based Features. Proc. SMM23, Workshop on Speech, Music and Mind 2023 (pp. 1–5). doi:10.21437/SMM.2023-1</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=%7BMispronunciation+detection+using+self-supervised+speech+representations%7D')"><td>2023</td><td>Vidal, J., Riera, P., & Ferrer, L. (2023). Mispronunciation detection using self-supervised speech representations. Proc. 9th Workshop on Speech and Language Technology in Education (SLaTE) (pp. 71–75). doi:10.21437/SLaTE.2023-15</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=%7BApparent+personality+prediction+from+speech+using+expert+features+and+wav2vec+2.0%7D')"><td>2023</td><td>Barchi, R., Pepino, L., Gauder, L., Estienne, L., Meza, M., Riera, P., & Ferrer, L. (2023). Apparent personality prediction from speech using expert features and wav2vec 2.0. Proc. SMM23, Workshop on Speech, Music and Mind 2023 (pp. 21–25). doi:10.21437/SMM.2023-5</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Phone+and+Speaker+Spatial+Organization+in+Self-Supervised+Speech+Representations')"><td>2023</td><td>Riera, P. E., Cerdeiro, M. A., Pepino, L., & Ferrer, L. (2023). Phone and speaker spatial organization in self-supervised speech representations. 2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW), pp. 1-5. URL: https://api.semanticscholar.org/CorpusID:257233071</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Towards+detecting+the+level+of+trust+in+the+skills+of+a+virtual+assistant+from+the+user%E2%80%99s+speech')"><td>2023</td><td>Gauder, L., Pepino, L., Riera, P., Brussino, S., Vidal, J., Gravano, A., & Ferrer, L. (2023). Towards detecting the level of trust in the skills of a virtual assistant from the user’s speech. Computer Speech & Language, p. 101487. URL: https://www.sciencedirect.com/science/article/pii/S0885230823000062, doi:https://doi.org/10.1016/j.csl.2023.101487</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=%7BAn+Electronic+Bandoneon+with+a+Dynamic+Sound+Synthesis+System+Based+on+Measured+Acoustic+Parameters%7D')"><td>2023</td><td>Ramos, J., Calcagno, E., Vergara, R., Rizza, J., & Riera, P. (2023 , 02). An Electronic Bandoneon with a Dynamic Sound Synthesis System Based on Measured Acoustic Parameters. Computer Music Journal, pp. 1-47. URL: https://doi.org/10.1162/comj\_a\_00636, arXiv:https://direct.mit.edu/comj/article-pdf/doi/10.1162/comj\_a\_00636/2071545/comj\_a\_00636.pdf, doi:10.1162/comj_a_00636</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Team+work+quality+prediction+using+speech-based+features')"><td>2023</td><td>Meza, M., Gauder, L., Estiene, L., Barchi, R., Gravano, A., Riera, P., & Ferrer, L. (2023). Team work quality prediction using speech-based features. Proc. SMM23, Workshop on Speech, Music and Mind 2023 (pp. 6–10).</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Bandoneon+2.0%3A+an+interdisciplinary+project+for+research+and+development+of+electronic+bandoneons+in+%7BArgentina%7D')"><td>2022</td><td>Ramos, J., Calcagno, E. R., Vergara, R. o., Riera, P., & Rizza, J. (2022 , jun 16). Bandoneon 2.0: an interdisciplinary project for research and development of electronic bandoneons in Argentina. NIME 2022. https://nime.pubpub.org/pub/31l4lgcd.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Study+of+Positional+Encoding+Approaches+for+Audio+Spectrogram+Transformers')"><td>2022</td><td>Pepino, L., Riera, P., & Ferrer, L. (2022). Study of positional encoding approaches for audio spectrogram transformers. ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 3713-3717). doi:10.1109/ICASSP43922.2022.9747742</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=A+Port+of+the+SuperCollider%E2%80%99s+Class+Library+to+Python')"><td>2022</td><td>Samaruga, L., & Riera, P. (2022). A port of the supercollider’s class library to python. Proceedings of the 17th International Audio Mostly Conference (pp. 137–142). New York, NY, USA: Association for Computing Machinery. URL: https://doi.org/10.1145/3561212.3561250, doi:10.1145/3561212.3561250</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=A+simple+and+cheap+setup+for+timing+tapping+responses+synchronized+to+auditory+stimuli')"><td>2021</td><td>Miguel, M. A., Riera, P., & Slezak, D. F. (2021 , Aug). A simple and cheap setup for timing tapping responses synchronized to auditory stimuli. Behavior Research Methods. URL: https://doi.org/10.3758/s13428-021-01653-y, doi:10.3758/s13428-021-01653-y</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=%7BEmotion+Recognition+from+Speech+Using+wav2vec+2.0+Embeddings%7D')"><td>2021</td><td>Pepino, L., Riera, P., & Ferrer, L. (2021). Emotion Recognition from Speech Using wav2vec 2.0 Embeddings. Proc. Interspeech 2021 (pp. 3400–3404). doi:10.21437/Interspeech.2021-703</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Alzheimer+Disease+Recognition+Using+Speech-Based+Embeddings+From+Pre-Trained+Models')"><td>2021</td><td>Gauder, L., Pepino, L., Ferrer, L., & Riera, P. (2021). Alzheimer disease recognition using speech-based embeddings from pre-trained models. Interspeech 2021 (pp. 3795–3799). doi:10.21437/Interspeech.2021-753</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Self-similarity+of+Classical+Music+Networks')"><td>2021</td><td>Rolla, V., Riera, P., Souza, P., Zubelli, J., & Velho, L. (2021). Self-similarity of classical music networks. Fractals, 29(2), 2150041–766.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Fusion+approaches+for+emotion+recognition+from+speech+using+acoustic+and+text-based+features')"><td>2020</td><td>Pepino, L., Riera, P., Ferrer, L., & Gravano, A. (2020). Fusion approaches for emotion recognition from speech using acoustic and text-based features. ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP).</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Teaching+Math+through+Music')"><td>2020</td><td>Riera, P. E. (2020). Teaching math through music. Instituto Nacional de Matemática Pura e Aplicada.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Ode%27s+ode')"><td>2019</td><td>Riera, P. E. (2019). Ode's ode. Live Coding Music IMPA. Instituto Nacional de Matemática Pura e Aplicada.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Analysing+the+impact+of+music+on+the+perception+of+red+wine+via+Temporal+Dominance+of+Sensations')"><td>2019</td><td>Wang, Q., Mesz, B., Riera, P., Trevisan, M., Sigman, M., Gruha, A., & Spence, C. (2019). Analysing the impact of music on the perception of red wine via temporal dominance of sensations. Multisensory Research.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=A+protocol+for+collecting+speech+data+with+varying+degrees+of+trust')"><td>2019</td><td>Gauder, L., Gravano, A., Ferrer, L., Riera, P., & Brussino, S. (2019). A protocol for collecting speech data with varying degrees of trust. Proc. SMM19, Workshop on Speech, Music and Mind 2019 (pp. 6–10).</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=No+Sample+Left+Behind%3A+Towards+a+Comprehensive+Evaluation+of+Speech+Emotion+Recognition+System')"><td>2019</td><td>Riera, P., Ferrer, L., Gravano, A., & Gauder, L. (2019). No sample left behind: towards a comprehensive evaluation of speech emotion recognition system. Proc. SMM19, Workshop on Speech, Music and Mind 2019.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Timbre+spaces+with+sparse+autoencoders')"><td>2017</td><td>Riera, P. E., Zabaljáuregui, M., & Eguía, M. C. (2017). Timbre spaces with sparse autoencoders. Proceedings of the 16th Brazilian Symposium on Computer Music.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Flexible+Solver+For+1-D+Cochlear+Partition+Simulations')"><td>2016</td><td>Riera, P. E., & Eguía, M. C. (2016). Flexible solver for 1-d cochlear partition simulations. Proceedings of the 22nd International Congress on Acoustics.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Multiple-scattering+theory+for+two-dimensional+arbitrarily+shaped+acoustic+composites')"><td>2016</td><td>Alberti, A., Spiousas, I., Riera, P. E., & Eguía, M. C. (2016). Multiple-scattering theory for two-dimensional arbitrarily shaped acoustic composites. Proceedings of the 22nd International Congress on Acoustics.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=A+Comparative+Study+of+Saxophone+Multiphonics%3A+Musical%2C+Psychophysical+and+Spectral+Analysis')"><td>2014</td><td>Riera, P. E., Proscia, M., & Eguía, M. C. (2014). A comparative study of saxophone multiphonics: musical, psychophysical and spectral analysis. Journal of New Music Research, pp. 1–12.</td></tr><tr data-name="Pablo_Riera" onclick="openUrl('https://scholar.google.com/scholar?q=Vocal+caricatures+reveal+signatures+of+speaker+identity')"><td>2013</td><td>López, S., Riera, P. E., Assaneo, M. F., Eguía, M., Sigman, M., & Trevisan, M. A. (2013). Vocal caricatures reveal signatures of speaker identity. Scientific reports, 3.</td></tr>
        </table>
        </body>
        </html>
        