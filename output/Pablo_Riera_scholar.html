
        <!DOCTYPE html>
        <html>
        <head>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                table { border-collapse: collapse; width: 100%; }
                th, td { padding: 8px; text-align: left; border-bottom: 1px solid #ddd; }
                th { background-color: #f2f2f2; }
                tr:hover { background-color: #f5f5f5; }
                h1 { color: #333; }
                .filter-links { margin-bottom: 20px; }
                .filter-links a {
                    margin-right: 15px;
                    text-decoration: none;
                    color: #0066cc;
                    padding: 5px 10px;
                    border-radius: 3px;
                    cursor: pointer;
                }
                .filter-links a.active {
                    background-color: #0066cc;
                    color: white;
                }
                .hidden { display: none; }
            </style>
            <script>
                function filterByName(name) {
                    const rows = document.querySelectorAll('table tr[data-name]');
                    const links = document.querySelectorAll('.filter-links a');
                    
                    links.forEach(link => {
                        if (link.getAttribute('data-name') === name || (name === 'all' && link.getAttribute('data-name') === 'all')) {
                            link.classList.add('active');
                        } else {
                            link.classList.remove('active');
                        }
                    });
                    
                    rows.forEach(row => {
                        if (name === 'all' || row.getAttribute('data-name') === name) {
                            row.classList.remove('hidden');
                        } else {
                            row.classList.add('hidden');
                        }
                    });
                }
            </script>
        </head>
        <body>
        <h1>Citations for Pablo_Riera</h1><div class="filter-links">
<a onclick="filterByName('all')" data-name="all" class="active">All</a>
<a onclick="filterByName('Pablo_Riera')" data-name="Pablo_Riera">Pablo Riera</a>
</div>

        <table>
            <tr><th>Year</th><th>Citation</th></tr>
        <tr data-name="Pablo_Riera"><td>2025</td><td>Riera, P. E. (2025). Cómo leer referencias de google scholar automáticamente.</td></tr><tr data-name="Pablo_Riera"><td>2024</td><td>García, A. M., Johann, F., Echegoyen, R., Calcaterra, C., Riera, P., Belloli, L., & Carrillo, F. (2024). Toolkit to examine lifelike language (tell): an app to capture speech and language markers of neurodegeneration. Behavior research methods, 56(4), 2886–2900.</td></tr><tr data-name="Pablo_Riera"><td>2024</td><td>Ferrer, L., & Riera, P. (2024). Confidence intervals for evaluation in machine learning. Computer software], Accessed, 1.</td></tr><tr data-name="Pablo_Riera"><td>2024</td><td>Vidal, J., Bonomi, C., Riera, P., & Ferrer, L. (2024). Automatic pronunciation assessment systems for english students from argentina. Communications of the ACM, 67(8), 63–67.</td></tr><tr data-name="Pablo_Riera"><td>2024</td><td>Gauder, L., Riera, P., Slachevsky, A., Forno, G., Garcia, A. M., & Ferrer, L. (2024). The unreliability of acoustic systems in alzheimer's speech datasets with heterogeneous recording conditions. arXiv preprint arXiv:2409.12170.</td></tr><tr data-name="Pablo_Riera"><td>2023</td><td>Gauder, L., Pepino, L., Riera, P., Brussino, S., Vidal, J., Gravano, A., & Ferrer, L. (2023). Towards detecting the level of trust in the skills of a virtual assistant from the user’s speech. Computer Speech & Language, 80, 101487.</td></tr><tr data-name="Pablo_Riera"><td>2023</td><td>Riera, P., Cerdeiro, M., Pepino, L., & Ferrer, L. (2023). Phone and speaker spatial organization in self-supervised speech representations. 2023 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW) (pp. 1–5).</td></tr><tr data-name="Pablo_Riera"><td>2023</td><td>Vidal, J., Riera, P., & Ferrer, L. (2023). Mispronunciation detection using self-supervised speech representations. Proc. 9th Workshop on Speech and Language Technology in Education (SLaTE) (pp. 71–75).</td></tr><tr data-name="Pablo_Riera"><td>2023</td><td>Barchi, R., Pepino, L., Gauder, L., Estienne, L., Meza, M., Riera, P., & Ferrer, L. (2023). Apparent personality prediction from speech using expert features and wav2vec 2.0. Proc. SMM 2023 (pp. 21–25).</td></tr><tr data-name="Pablo_Riera"><td>2023</td><td>Pepino, L., Riera, P., & Ferrer, L. (2023). Encodecmae: leveraging neural codecs for universal audio representation learning. arXiv preprint arXiv:2309.07391.</td></tr><tr data-name="Pablo_Riera"><td>2023</td><td>Ramos, J. M., Calcagno, E. R., & Riera, P. E. (2023). An embedded wavetable synthesizer for the electronic bandoneon with parameter mappings based on acoustical measurements. Proceedings of the International Conference on New Interfaces for Musical Expression.</td></tr><tr data-name="Pablo_Riera"><td>2022</td><td>Miguel, M. A., Riera, P., & Slezak, D. F. (2022). A simple and cheap setup for timing tapping responses synchronized to auditory stimuli. Behavior Research Methods, 54(2), 712–728.</td></tr><tr data-name="Pablo_Riera"><td>2022</td><td>Pepino, L., Riera, P., & Ferrer, L. (2022). Study of positional encoding approaches for audio spectrogram transformers. ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 3713–3717).</td></tr><tr data-name="Pablo_Riera"><td>2022</td><td>Pareyon, G., Almada, C., Mathias, C., Saraiva, C., Moreira, D., Carvalho, H., … others. (2022). Music and mathematics in latin america. major developments in the last 25 years. Brazilian Journal of Music and Mathematics, 6(1), 12–47.</td></tr><tr data-name="Pablo_Riera"><td>2022</td><td>Samaruga, L., & Riera, P. (2022). A port of the supercollider’s class library to python. Proceedings of the 17th International Audio Mostly Conference (pp. 137–142).</td></tr><tr data-name="Pablo_Riera"><td>2022</td><td>Pepino, L., Riera, P., Barchi, G., & Giaccio, J. (2022). Sistema de conversión de texto a habla en español con control de acento, prosodia y clonación de voz. Memorias de las JAIIO, 8(2), 110–111.</td></tr><tr data-name="Pablo_Riera"><td>2022</td><td>Ramos, J., Calcagno, E. R., oscar Vergara, R., Riera, P., & Rizza, J. (2022). Bandoneon 2.0: an interdisciplinary project for research and development of electronic bandoneons in argentina. NIME 2022.</td></tr><tr data-name="Pablo_Riera"><td>2022</td><td>Ramos, J., Calcagno, E., Vergara, R., Rizza, J., & Riera, P. (2022). An electronic bandoneon with a dynamic sound synthesis system based on measured acoustic parameters. Computer Music Journal, 46(1-2), 40–57.</td></tr><tr data-name="Pablo_Riera"><td>2021</td><td>Rolla, V., Riera, P., Souza, P., Zubelli, J., & Velho, L. (2021). Self-similarity of classical music networks. Fractals, 29(02), 2150041.</td></tr><tr data-name="Pablo_Riera"><td>2021</td><td>Gauder, L., Pepino, L., Riera, P., Brussino, S., Vidal, J., Gravano, A., & Ferrer, L. (2021). A study on the manifestation of trust in speech. arXiv preprint arXiv:2102.09370.</td></tr><tr data-name="Pablo_Riera"><td>2021</td><td>Pepino, L., Riera, P., & Ferrer, L. (2021). Emotion recognition from speech using wav2vec 2.0 embeddings. Proc. Interspeech 2021 (pp. 3400–3404).</td></tr><tr data-name="Pablo_Riera"><td>2020</td><td>Pepino, L., Riera, P., Ferrer, L., & Gravano, A. (2020). Fusion approaches for emotion recognition from speech using acoustic and text-based features. ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 6484–6488).</td></tr><tr data-name="Pablo_Riera"><td>2020</td><td>Pepino, L., Riera, P., Gauder, L., Gravano, A., & Ferrer, L. (2020). Detecting distrust towards the skills of a virtual assistant using speech. arXiv preprint arXiv:2007.15711.</td></tr><tr data-name="Pablo_Riera"><td>2020</td><td>Gauder, L., Riera, P., Pepino, L., Brussino, S., Vidal, J., Ferrer, L., & Gravano, A. (2020). Trust-uba: a corpus for the study of the manifestation of trust in speech. arXiv preprint arXiv:2006.05977.</td></tr><tr data-name="Pablo_Riera"><td>2019</td><td>Wang, Q. J., Mesz, B., Riera, P., Trevisan, M., Sigman, M., Guha, A., & Spence, C. (2019). Analysing the impact of music on the perception of red wine via temporal dominance of sensations. Multisensory Research, 32(4-5), 455–472.</td></tr><tr data-name="Pablo_Riera"><td>2019</td><td>Riera, P., Ferrer, L., Gravano, A., & Gauder, L. (2019). No sample left behind: towards a comprehensive evaluation of speech emotion recognition system. Proc. Workshop on Speech, Music and Mind 2019.</td></tr><tr data-name="Pablo_Riera"><td>2018</td><td>Proscia, M., Riera, P. E., & Eguia, M. C. (2018). T7p: short talks 7-acoustics and philosphy. 15th International Conference on Music Perception and Cognition 10th triennial conference of the European Society for the Cognitive Sciences of Music (p. 400).</td></tr><tr data-name="Pablo_Riera"><td>2017</td><td>Proscia, M., Riera, P. E., & Eguia, M. C. (2017). A timbral and a musical performance analysis of saxophone multiphonic morphings. Congreso ISMA.</td></tr><tr data-name="Pablo_Riera"><td>2017</td><td>Riera, P. E., Eguía, M., & Zabaljáuregui, M. (2017). Timbre spaces with sparse autoencoders. Brazilian Symposium on Computer Music, 16. Proceedings... Sao Paulo: SBC (pp. 93–98).</td></tr><tr data-name="Pablo_Riera"><td>2016</td><td>Alberti, A., Spiousas, I., Riera, P., & Eguía, M. (2016). Multiple-scattering theory for two-dimensional arbitrarily shaped acoustic composites. Proceedings of Meetings on Acoustics.</td></tr><tr data-name="Pablo_Riera"><td>2016</td><td>Riera, P. E., & Eguía, M. C. (2016). Flexible solver for 1-d cochlear partition simulations. Proceedings of Meetings on Acoustics.</td></tr><tr data-name="Pablo_Riera"><td>2015</td><td>Riera, P. E. (2015). Estudio de la percepción tímbrica en sonidos con modulación mediante experimentos psicofísicos y modelado de la periferia auditiva (Doctoral dissertation). Universidad de Buenos Aires. Facultad de Ciencias Exactas y Naturales.</td></tr><tr data-name="Pablo_Riera"><td>2014</td><td>Riera, P. E., Proscia, M., & Eguia, M. C. (2014). A comparative study of saxophone multiphonics: musical, psychophysical and spectral analysis. Journal of New Music Research, 43(2), 202–213.</td></tr><tr data-name="Pablo_Riera"><td>2013</td><td>López, S., Riera, P., Assaneo, M. F., Eguía, M., Sigman, M., & Trevisan, M. A. (2013). Vocal caricatures reveal signatures of speaker identity. Scientific reports, 3(1), 3407.</td></tr><tr data-name="Pablo_Riera"><td>2012</td><td>Proscia, M., Riera, P., & Eguia, M. (2012). Comparative study of saxophone multiphonic tones: a possible perceptual categorization. Proceedings of the 12th International Conference on Music Perception and Cognition and the 8th Triennial Conference of the European Society for Cogniitve Sciences of Music (p. 822).</td></tr><tr data-name="Pablo_Riera"><td>2011</td><td>Kerlleñevich, H., Riera, P. E., & Eguia, M. C. (2011). Santiago-a real-time biological neural network environment for generative music creation. Applications of Evolutionary Computation: EvoApplications 2011: EvoCOMNET, EvoFIN, EvoHOT, EvoMUSART, EvoSTIM, and EvoTRANSLOG, Torino, Italy, April 27-29, 2011, Proceedings, Part II (pp. 344–353).</td></tr><tr data-name="Pablo_Riera"><td>2011</td><td>PROSCIA, M., RIERA, P., & EGUIA, M. (2011). Estudio comparativo del saxofón multifónico a partir de diferentes herramientas de análisis perceptivo. Musicalidad Humana: Debates actuales en evolución, desarrollo y cognición e implicancias socio-culturales: Actas del X Encuentro de Ciencias Cognitivas de la Musica. Buenos Aires: SAACoM, pp. 317–325.</td></tr><tr data-name="Pablo_Riera"><td>2011</td><td>Kerlleñevich, H., Riera, P., & Eguia, M. (2011). An open source interface based on biological neural networks for interactive music performance. New Interfaces for Musical Expression.</td></tr><tr data-name="Pablo_Riera"><td>2008</td><td>Eguia, M. C., Mesz, B. A., & Riera, P. (2008). Fine temporal coding in the auditory system: a model for vibrato perception. Neurolatam I.</td></tr>
        </table>
        </body>
        </html>
        